以下是将上述内容转化为 Markdown 格式的版本，您可以直接保存为 `.md` 文件。

---

# 模型说明及代码

## 初版模型

### 1）模型说明

1. 将线性梯度下降模型封装成了一个函数，可以通过直接调用，修改上传的训练数据集的位置、学习率和训练的轮数。
2. 将每一次模型训练的存档保存到指定位置的 `.txt` 类型文件中，方便后续查看。
3. 自己定义了一个考虑训练时间的损失函数，并且通过时间权重，对模型训练时间做出优化。
4. 通过 `matplotlib`，绘制出了模型中数据点的散点图，和模型拟合出的最终图像。

### 2）效果展示

效果展示在后续的模型效果部分。

### 3）代码

```python
import torch
import numpy as np
import matplotlib.pyplot as plt
import time

def train_with_custom_loss(data_path, output_path, initial_lr=1e-2, num_epochs=100, time_weight=0.1):
    # 读取数据
    data = np.loadtxt(data_path, delimiter=',')
    x_train = data[:, 0].reshape(-1, 1)  # 取第一列作为X特征
    y_train = data[:, 1].reshape(-1, 1)  # 取第二列作为y目标值

    # 转换为 PyTorch 张量
    x_train = torch.tensor(x_train, dtype=torch.float32, requires_grad=False)
    y_train = torch.tensor(y_train, dtype=torch.float32, requires_grad=False)

    # 初始化权重和偏置
    w = torch.randn(1, requires_grad=True)
    b = torch.zeros(1, requires_grad=True)

    # 定义线性模型
    def linear_model(x):
        return x * w + b

    # 定义误差损失
    def get_loss(y_pred, y_true):
        return torch.mean((y_pred - y_true) ** 2)

    # 初始化变量
    best_loss = float('inf')
    best_w, best_b = None, None
    lr = initial_lr  # 学习率

    # 创建/打开输出文件
    with open(output_path, 'w') as f:
        f.write("Epoch\tTraining Time (s)\tTraining Loss\tLinear Equation\n")

    # 记录训练开始时间
    total_start_time = time.time()

    for epoch in range(num_epochs):
        start_time = time.time()

        # 前向传播
        y_pred = linear_model(x_train)
        mse_loss = get_loss(y_pred, y_train)

        # 记录当前训练时间
        epoch_time = time.time() - start_time

        # 构造新的损失函数
        normalized_time = epoch_time / (1 + epoch_time)  # 归一化时间
        custom_loss = mse_loss + time_weight * normalized_time

        # 反向传播
        custom_loss.backward()

        # 更新权重和偏置
        with torch.no_grad():
            w -= lr * w.grad
            b -= lr * b.grad

        # 清零梯度
        w.grad.zero_()
        b.grad.zero_()

        # 动态调整学习率
        if mse_loss < best_loss:
            best_loss = mse_loss
            best_w, best_b = w.clone(), b.clone()
        else:
            lr *= 0.9  # 如果损失没有改善，降低学习率

        # 存储当前模型信息到文件
        linear_eq = f"y = {w.item():.4f}x + {b.item():.4f}"
        with open(output_path, 'a') as f:
            f.write(f"{epoch+1}\t{epoch_time:.6f}\t{mse_loss.item():.6f}\t{linear_eq}\n")

    # 计算总训练时间
    total_training_time = time.time() - total_start_time

    # 最终预测
    y_final = linear_model(x_train).detach()

    # 绘制最终模型结果
    plt.plot(x_train.numpy(), y_train.numpy(), 'bo', label='Real data')
    plt.plot(x_train.numpy(), y_final.numpy(), 'r-', label=f'Best Model: y = {best_w.item()}x + {best_b.item()}')
    plt.legend()
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.title('Linear Regression with Custom Loss')
    plt.show()

    print(f"Best Loss: {best_loss}")
    print(f"Total Training Time: {total_training_time} seconds")
    print(f"Final Model: w = {best_w.item()}, b = {best_b.item()}")

    # 返回最终信息
    return best_w.item(), best_b.item(), total_training_time

# 使用例子
data_path = 'D:/edge浏览器下载/data (1).txt'  # 数据文件路径
output_path = 'D:/edge浏览器下载/model_archive.txt'  # 输出文件路径
initial_lr = 1e-2  # 初始学习率
num_epochs = 10000  # 最大训练轮数
time_weight = 0.1  # 时间损失的权重

best_w, best_b, total_training_time = train_with_custom_loss(data_path, output_path, initial_lr, num_epochs, time_weight)
output_path = r"C:\Users\Administrator\Desktop\梯度下降训练模型存档\model_archive.txt"
```

---




