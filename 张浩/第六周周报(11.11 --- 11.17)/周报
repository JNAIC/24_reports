这周进行的内容主要有两个：吴恩达的网课和看这本书《python神经网络编程》
一.吴恩达：
  1.学习了二分分类和logistic回归，以及计算它的损失函数，还有梯度下降法
  2.学习了m个样本如何进行正向传播和反向传播，以及实现他们的向量化
  3.学习了在使用激活函数之后的神经网络正向传播以及反向传播是怎样的，还有要使用非线性的激活函数，比如Rule， sigmoid函数等等
  4.了解了深层的神经网络，即含有多个隐藏层的神经网络，最重要的是学会了如何利用矩阵的维数来判断权重或者输入是否要转置等

二。《python神经网络编程》
  1.将书的前两章内容看完了，了解了神经网络是如何进行工作的，并学会了如何计算使用sigmoid函数作为激活函数时的梯度下降法求偏导
  2.实际操作了本书第二章的那个例子，即学会了如何训练判断手写数字的数据集MNIST
  3.写这个程序给我的经验是：初始化权重要尽量小，设置的隐藏层节点数量要适中，不能太少也不能太大，还要调整合适的学习率，以达到更好的拟合效果
